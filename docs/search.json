[
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Setup",
    "section": "",
    "text": "We will be utilising Google Colab, you will need a google account to use this service."
  },
  {
    "objectID": "setup.html#optional.-singularity-access-on-artemis",
    "href": "setup.html#optional.-singularity-access-on-artemis",
    "title": "Setup",
    "section": "Optional. Singularity Access on Artemis",
    "text": "Optional. Singularity Access on Artemis\nIf you require the Singularity versions of AlphaFold, please log a request to be given access to Singularity."
  },
  {
    "objectID": "setup.html#a.-linux-systems",
    "href": "setup.html#a.-linux-systems",
    "title": "Setup",
    "section": "A. Linux systems",
    "text": "A. Linux systems\nIf you use Linux, then chances are you already have a shell. Open your preferred terminal program and off you go! An X-Window server (X11) may also be useful if you want to be able to use GUIs.\nConnection to Artemis can be made via ssh by issuing the following command on the shell:\nssh -X &lt;unikey&gt;@hpc.sydney.edu.au"
  },
  {
    "objectID": "setup.html#b.-osx-mac-computers-and-laptops",
    "href": "setup.html#b.-osx-mac-computers-and-laptops",
    "title": "Setup",
    "section": "B. OSX (Mac computers and laptops)",
    "text": "B. OSX (Mac computers and laptops)\nMac operating systems come with a terminal program, called Terminal. Just look for it in your Applications folder, or hit Command-Space and type ‘terminal’.\n\n\n\nTerminal is OSX’s native terminal emulator.\n\n\n\nWe also recommend installing XQuartz, which will replace OSX’s native X-Window server. XQuartz has some extra features that may offer better performance when using GUI programs. You’ll need to log out and back in again after installing XQuartz in order for it to activate.\nConnection to Artemis can be made via ssh by issuing the following command in the terminal:\nssh -X &lt;unikey&gt;@hpc.sydney.edu.au"
  },
  {
    "objectID": "setup.html#c.-windows",
    "href": "setup.html#c.-windows",
    "title": "Setup",
    "section": "C. Windows",
    "text": "C. Windows\nWindows has a couple of terminal programs and shells buried in the Programs menu (cmd, powershell). However, those aren’t going to work for us, as you’ll need extra programs and utilities to connect to Artemis, such as an SSH implementation. To use Artemis on Windows, you have a couple of options:\n\nOption i. PuTTY (Easy)\nPuTTY, an SSH and telnet client, is a good simple option.\nHead to the PuTTY Website and download PuTTY. You can install it to your computer, or just download the ‘binary’ and run it directly. Create a new session for use with Artemis as follows:\n\nFill in the connection details:\n\n\nHost Name: hpc.sydney.edu.au\nPort: 22\nConnection type: SSH\n\n\n\nName this session “Artemis” and click ‘Save’\n\nNote that PuTTY does not provide an X11 server natievly, so you won’t be able to use GUI programs on Artemis with just PuTTY. You can optionally install VcXsrv or similar to enable X-11 forwarding).\n\n\nOption ii. WSL and Ubuntu (Advanced)\nInstall Ubuntu or some other Linux distro on the Windows Subsystem for Linux see here for details. This one will give you the full suite of Linux functions."
  },
  {
    "objectID": "notebooks/03_artemis.html",
    "href": "notebooks/03_artemis.html",
    "title": "Running AlphaFold on the Artemis HPC",
    "section": "",
    "text": "AlphaFold can be accessed by executing\nmodule load alphafold\nThere are several (large) genetic databases and parameters AlphaFold requires. Different versions of these are conveniently available on Artemis in the common folder: /project/data/alphafold2/ If there is additional databases you require, please fill in a support ticket.\nTo actually run a computationally intensive AlphaFold job, we must create a PBS jobscript, which is a standard shell script with a few PBS-specific directives, that is sent to the job scheduler for execution. Most requirements are on Artemis already, but you must bring your own .fasta file.\n\n\nWhen connecting to Artemis you will be in the directory /home/&lt;unikey&gt;. This folder has 10gb of storage only, so is not ideal to run computational work from. Rather, consider the /scratch and /project directories. For our demo, we will work in the Training project in a sub-folder of our creation. Your projects in the /project folder have up to 1TB of storage space available shared between other members of your project.\nFollow these steps to navigate to the project folder and create a new directory, and download some example data.\ncd /project/Training\nmkdir demo1\ncd demo1\nwget https://github.com/Sydney-Informatics-Hub/training.alphafold/raw/main/af_demo.zip\nunzip af_demo.zip\ncd af_demo\nExecuting the command\npwd\nshould print the current working directory:\n/project/Training/demo1/af_demo\n\n\n\n\nFasta files are simply text. You can make one right in your jobscript or on the command line with these commands, for example:\necho \"&gt;T1084 Meio, Meiothermus silvanus, 73 residues|\" &gt; demo.fasta\necho \"MAAHKGAEHHHKAAEHHEQAAKHHHAAAEHHEKGEHEQAAHHADTAYAHHKHAEEHAAQAAKHDAEHHAPKPH\" &gt;&gt; demo.fasta\n\n\n\nMake a new file called alpha_job.pbs. Execute nano alpha_job.pbs to edit a new text file in the nano text-editor. Make the changes then hit cntrl+x to exit the nano text-editor, save the changes as prompted.\nThe contents at a minimum, should look something like this.\n#!/bin/bash\n\n#PBS -P Training\n#PBS -l select=1:ncpus=8:mem=32gb:ngpus=0\n#PBS -l walltime=48:00:00\n#PBS -N job01\n\n# Load necessary modules (on Artemis, this will load the correct python environment with AlphaFold installed)\nmodule load alphafold/2.2.0-cpu hmmer hh-suite kalign\n\n# Navigate to your directory\n# $PBS_O_WORKDIR is an alias for \"the folder you submit your job in\", likely /project/Training/demo1/af_demo or similar.\ncd $PBS_O_WORKDIR\n\n# Make a directory to save output data to\nOUTDIR=${PBS_O_WORKDIR}/${PBS_JOBNAME}_output\nmkdir -p $OUTDIR\n\n# Set the alphafold base database directory. Visit this folder to see other options.\nexport ALPHADB=/project/data/alphafold2/20220323\n\n# Run the AlphaFold2 prediction command. Note most database paths are required\nrun_alphafold.py \\\n        --fasta_paths=/project/Training/DATA/input.fasta \\\n        --output_dir=${OUTDIR} \\\n        --data_dir=${ALPHADB} \\\n        --uniref90_database_path=${ALPHADB}/uniref90/uniref90.fasta \\\n        --mgnify_database_path=${ALPHADB}/mgnify/mgy_clusters_2018_12.fa \\\n        --template_mmcif_dir=${ALPHADB}/pdb_mmcif/mmcif_files/ \\\n        --obsolete_pdbs_path=${ALPHADB}/pdb_mmcif/obsolete.dat \\\n        --db_preset=full_dbs \\\n        --max_template_date=2022-03-23 \\\n        --use_gpu_relax=False \\\n        --model_preset=monomer \\\n        --pdb70_database_path=${ALPHADB}/pdb70/pdb70 \\\n        --bfd_database_path=${ALPHADB}/bfd/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt \\\n        --uniclust30_database_path=${ALPHADB}/uniclust30/uniclust30_2018_08/uniclust30_2018_08\n\n\n\nNow we can submit the job to the scheduler\nqsub alpha_job.pbs\nThis will execute when compute resources become available. Check the status with:\nqstat -x -u &lt;unikey&gt;\n\n\nBy default, several output files will be generated.\n\n\nBy default, at the completion of a job (successful or otherwise) these 3 output files will be generated in the folder in which the job was submitted.\n\nPBS job outputs\n\n\n\n\n\n\nJobName.eJobID\nContains error/warning messages – those usually printed to stderr\n\n\nJobName.oJobID\nContains output messages – those usually printed to stdout\n\n\nJobName.oJobID_usage\nshort summary of the resources used by your job\n\n\n\nIf your job has not completed successfully or AlphaFold outputs have not been generated as expected, these files may help diagnose what wen wrong (or inform you what went right!)\n\n\n\nUsing the configuration options above will produce output in the folder specified, i.e:\n--output_dir=${OUTDIR}\nIn our case, this should resolve to the directory\n/project/Training/demo1/output_directory\nThis folder will be created by AlphaFold if it does not exist, and will contain the predicted structures of the target protein represented in the following key files - but may vary depending on the options in your job.\n\nAF outputs\n\n\n\n\n\n\nmsas\nFolder of intermediate step output from other tools (hmmer, kalign) used to construct the input MSA.\n\n\ntimings.json\nA JSON format text file containing the times taken to run each section of the AlphaFold pipeline.\n\n\nranking_debug.json\nA JSON format text file containing the pLDDT values used to perform the model ranking, and a mapping back to the original model names.\n\n\nfeatures.pkl\nA Python pickle file containing the input feature NumPy arrays used by the models to produce the structures.\n\n\nresult_model_*.pkl\n\n\n\nranked_*.pdb\nA PDB format text file containing the predicted structures, after reordering by model confidence.\n\n\nrelaxed_model_*.pdb\nA PDB format text file containing the predicted structure, after performing an Amber relaxation procedure on the unrelaxed structure prediction\n\n\nunrelaxed_model_*.pdb\nA PDB format text file containing the predicted structure, exactly as outputted by the model.\n\n\n\n\n\n\n\nQuick-view an example of the output (note: this requires X-11 forwarding to be enabled when connected to Artemis):\nqsub -X -I -P Training\nmodule load pymol/2.4.0\npymol example.pbd\n\n\n\n\nThe below script will run the same workflow, but leverage the GPU in certain steps. Keep in mind, on Artemis, the GPUs are in high-demand so you may have to wait longer in the queue.\n#!/bin/bash\n\n#PBS -P Training\n#PBS -l select=1:ncpus=8:mem=32gb:ngpus=1\n#PBS -l walltime=48:00:00\n#PBS -N job01_gpu\n\n# Load necessary modules (on Artemis, this will load the correct python environment with AlphaFold installed)\nmodule load alphafold/2.2.0-cpu hmmer hh-suite kalign\n\n# Navigate to your directory\n# $PBS_O_WORKDIR is an alias for \"the folder you submit your job in\", likely /project/Training/ or similar.\ncd $PBS_O_WORKDIR\n\n# Make a directory to save output data to\nOUTDIR=${PBS_O_WORKDIR}/${PBS_JOBNAME}_output\nmkdir -p $OUTDIR\n\n# You must install extra packages in the python environment that is loaded with alphafold\npip install -U https://storage.googleapis.com/jax-releases/cuda102/jaxlib-0.1.71+cuda102-cp37-none-manylinux2010_x86_64.whl\npip install -U jax==0.2.25\n\n# Set the alphafold base database directory. Visit this folder to see other options.\nexport ALPHADB=/project/data/alphafold2/20220323\n\n# Run the AlphaFold2 prediction command. Note most database paths are required\nrun_alphafold.py \\\n        --fasta_paths=/project/Training/DATA/input.fasta \\\n        --output_dir=${OUTDIR} \\\n        --data_dir=${ALPHADB} \\\n        --uniref90_database_path=${ALPHADB}/uniref90/uniref90.fasta \\\n        --mgnify_database_path=${ALPHADB}/mgnify/mgy_clusters_2018_12.fa \\\n        --template_mmcif_dir=${ALPHADB}/pdb_mmcif/mmcif_files/ \\\n        --obsolete_pdbs_path=${ALPHADB}/pdb_mmcif/obsolete.dat \\\n        --db_preset=full_dbs \\\n        --max_template_date=2022-03-23 \\\n        --use_gpu_relax=False \\\n        --model_preset=monomer \\\n        --pdb70_database_path=${ALPHADB}/pdb70/pdb70 \\\n        --bfd_database_path=${ALPHADB}/bfd/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt \\\n        --uniclust30_database_path=${ALPHADB}/uniclust30/uniclust30_2018_08/uniclust30_2018_08\nFor this simple example, with 8cpus and 32gb RAM, it will take around 35 hours. Only the final step is GPU optimised, reducing the time to 34 hours."
  },
  {
    "objectID": "notebooks/03_artemis.html#alphafold-on-artemis",
    "href": "notebooks/03_artemis.html#alphafold-on-artemis",
    "title": "Running AlphaFold on the Artemis HPC",
    "section": "",
    "text": "AlphaFold can be accessed by executing\nmodule load alphafold\nThere are several (large) genetic databases and parameters AlphaFold requires. Different versions of these are conveniently available on Artemis in the common folder: /project/data/alphafold2/ If there is additional databases you require, please fill in a support ticket.\nTo actually run a computationally intensive AlphaFold job, we must create a PBS jobscript, which is a standard shell script with a few PBS-specific directives, that is sent to the job scheduler for execution. Most requirements are on Artemis already, but you must bring your own .fasta file.\n\n\nWhen connecting to Artemis you will be in the directory /home/&lt;unikey&gt;. This folder has 10gb of storage only, so is not ideal to run computational work from. Rather, consider the /scratch and /project directories. For our demo, we will work in the Training project in a sub-folder of our creation. Your projects in the /project folder have up to 1TB of storage space available shared between other members of your project.\nFollow these steps to navigate to the project folder and create a new directory, and download some example data.\ncd /project/Training\nmkdir demo1\ncd demo1\nwget https://github.com/Sydney-Informatics-Hub/training.alphafold/raw/main/af_demo.zip\nunzip af_demo.zip\ncd af_demo\nExecuting the command\npwd\nshould print the current working directory:\n/project/Training/demo1/af_demo"
  },
  {
    "objectID": "notebooks/03_artemis.html#optional-generate-a-fasta-file",
    "href": "notebooks/03_artemis.html#optional-generate-a-fasta-file",
    "title": "Running AlphaFold on the Artemis HPC",
    "section": "",
    "text": "Fasta files are simply text. You can make one right in your jobscript or on the command line with these commands, for example:\necho \"&gt;T1084 Meio, Meiothermus silvanus, 73 residues|\" &gt; demo.fasta\necho \"MAAHKGAEHHHKAAEHHEQAAKHHHAAAEHHEKGEHEQAAHHADTAYAHHKHAEEHAAQAAKHDAEHHAPKPH\" &gt;&gt; demo.fasta"
  },
  {
    "objectID": "notebooks/03_artemis.html#make-a-pbs-jobscript",
    "href": "notebooks/03_artemis.html#make-a-pbs-jobscript",
    "title": "Running AlphaFold on the Artemis HPC",
    "section": "",
    "text": "Make a new file called alpha_job.pbs. Execute nano alpha_job.pbs to edit a new text file in the nano text-editor. Make the changes then hit cntrl+x to exit the nano text-editor, save the changes as prompted.\nThe contents at a minimum, should look something like this.\n#!/bin/bash\n\n#PBS -P Training\n#PBS -l select=1:ncpus=8:mem=32gb:ngpus=0\n#PBS -l walltime=48:00:00\n#PBS -N job01\n\n# Load necessary modules (on Artemis, this will load the correct python environment with AlphaFold installed)\nmodule load alphafold/2.2.0-cpu hmmer hh-suite kalign\n\n# Navigate to your directory\n# $PBS_O_WORKDIR is an alias for \"the folder you submit your job in\", likely /project/Training/demo1/af_demo or similar.\ncd $PBS_O_WORKDIR\n\n# Make a directory to save output data to\nOUTDIR=${PBS_O_WORKDIR}/${PBS_JOBNAME}_output\nmkdir -p $OUTDIR\n\n# Set the alphafold base database directory. Visit this folder to see other options.\nexport ALPHADB=/project/data/alphafold2/20220323\n\n# Run the AlphaFold2 prediction command. Note most database paths are required\nrun_alphafold.py \\\n        --fasta_paths=/project/Training/DATA/input.fasta \\\n        --output_dir=${OUTDIR} \\\n        --data_dir=${ALPHADB} \\\n        --uniref90_database_path=${ALPHADB}/uniref90/uniref90.fasta \\\n        --mgnify_database_path=${ALPHADB}/mgnify/mgy_clusters_2018_12.fa \\\n        --template_mmcif_dir=${ALPHADB}/pdb_mmcif/mmcif_files/ \\\n        --obsolete_pdbs_path=${ALPHADB}/pdb_mmcif/obsolete.dat \\\n        --db_preset=full_dbs \\\n        --max_template_date=2022-03-23 \\\n        --use_gpu_relax=False \\\n        --model_preset=monomer \\\n        --pdb70_database_path=${ALPHADB}/pdb70/pdb70 \\\n        --bfd_database_path=${ALPHADB}/bfd/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt \\\n        --uniclust30_database_path=${ALPHADB}/uniclust30/uniclust30_2018_08/uniclust30_2018_08"
  },
  {
    "objectID": "notebooks/03_artemis.html#submit-a-pbs-jobscript-to-the-queue",
    "href": "notebooks/03_artemis.html#submit-a-pbs-jobscript-to-the-queue",
    "title": "Running AlphaFold on the Artemis HPC",
    "section": "",
    "text": "Now we can submit the job to the scheduler\nqsub alpha_job.pbs\nThis will execute when compute resources become available. Check the status with:\nqstat -x -u &lt;unikey&gt;\n\n\nBy default, several output files will be generated.\n\n\nBy default, at the completion of a job (successful or otherwise) these 3 output files will be generated in the folder in which the job was submitted.\n\nPBS job outputs\n\n\n\n\n\n\nJobName.eJobID\nContains error/warning messages – those usually printed to stderr\n\n\nJobName.oJobID\nContains output messages – those usually printed to stdout\n\n\nJobName.oJobID_usage\nshort summary of the resources used by your job\n\n\n\nIf your job has not completed successfully or AlphaFold outputs have not been generated as expected, these files may help diagnose what wen wrong (or inform you what went right!)\n\n\n\nUsing the configuration options above will produce output in the folder specified, i.e:\n--output_dir=${OUTDIR}\nIn our case, this should resolve to the directory\n/project/Training/demo1/output_directory\nThis folder will be created by AlphaFold if it does not exist, and will contain the predicted structures of the target protein represented in the following key files - but may vary depending on the options in your job.\n\nAF outputs\n\n\n\n\n\n\nmsas\nFolder of intermediate step output from other tools (hmmer, kalign) used to construct the input MSA.\n\n\ntimings.json\nA JSON format text file containing the times taken to run each section of the AlphaFold pipeline.\n\n\nranking_debug.json\nA JSON format text file containing the pLDDT values used to perform the model ranking, and a mapping back to the original model names.\n\n\nfeatures.pkl\nA Python pickle file containing the input feature NumPy arrays used by the models to produce the structures.\n\n\nresult_model_*.pkl\n\n\n\nranked_*.pdb\nA PDB format text file containing the predicted structures, after reordering by model confidence.\n\n\nrelaxed_model_*.pdb\nA PDB format text file containing the predicted structure, after performing an Amber relaxation procedure on the unrelaxed structure prediction\n\n\nunrelaxed_model_*.pdb\nA PDB format text file containing the predicted structure, exactly as outputted by the model.\n\n\n\n\n\n\n\nQuick-view an example of the output (note: this requires X-11 forwarding to be enabled when connected to Artemis):\nqsub -X -I -P Training\nmodule load pymol/2.4.0\npymol example.pbd"
  },
  {
    "objectID": "notebooks/03_artemis.html#using-the-gpu",
    "href": "notebooks/03_artemis.html#using-the-gpu",
    "title": "Running AlphaFold on the Artemis HPC",
    "section": "",
    "text": "The below script will run the same workflow, but leverage the GPU in certain steps. Keep in mind, on Artemis, the GPUs are in high-demand so you may have to wait longer in the queue.\n#!/bin/bash\n\n#PBS -P Training\n#PBS -l select=1:ncpus=8:mem=32gb:ngpus=1\n#PBS -l walltime=48:00:00\n#PBS -N job01_gpu\n\n# Load necessary modules (on Artemis, this will load the correct python environment with AlphaFold installed)\nmodule load alphafold/2.2.0-cpu hmmer hh-suite kalign\n\n# Navigate to your directory\n# $PBS_O_WORKDIR is an alias for \"the folder you submit your job in\", likely /project/Training/ or similar.\ncd $PBS_O_WORKDIR\n\n# Make a directory to save output data to\nOUTDIR=${PBS_O_WORKDIR}/${PBS_JOBNAME}_output\nmkdir -p $OUTDIR\n\n# You must install extra packages in the python environment that is loaded with alphafold\npip install -U https://storage.googleapis.com/jax-releases/cuda102/jaxlib-0.1.71+cuda102-cp37-none-manylinux2010_x86_64.whl\npip install -U jax==0.2.25\n\n# Set the alphafold base database directory. Visit this folder to see other options.\nexport ALPHADB=/project/data/alphafold2/20220323\n\n# Run the AlphaFold2 prediction command. Note most database paths are required\nrun_alphafold.py \\\n        --fasta_paths=/project/Training/DATA/input.fasta \\\n        --output_dir=${OUTDIR} \\\n        --data_dir=${ALPHADB} \\\n        --uniref90_database_path=${ALPHADB}/uniref90/uniref90.fasta \\\n        --mgnify_database_path=${ALPHADB}/mgnify/mgy_clusters_2018_12.fa \\\n        --template_mmcif_dir=${ALPHADB}/pdb_mmcif/mmcif_files/ \\\n        --obsolete_pdbs_path=${ALPHADB}/pdb_mmcif/obsolete.dat \\\n        --db_preset=full_dbs \\\n        --max_template_date=2022-03-23 \\\n        --use_gpu_relax=False \\\n        --model_preset=monomer \\\n        --pdb70_database_path=${ALPHADB}/pdb70/pdb70 \\\n        --bfd_database_path=${ALPHADB}/bfd/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt \\\n        --uniclust30_database_path=${ALPHADB}/uniclust30/uniclust30_2018_08/uniclust30_2018_08\nFor this simple example, with 8cpus and 32gb RAM, it will take around 35 hours. Only the final step is GPU optimised, reducing the time to 34 hours."
  },
  {
    "objectID": "notebooks/07_colabfold.html",
    "href": "notebooks/07_colabfold.html",
    "title": "Running AlphaFold with ColabFold on Google Colab",
    "section": "",
    "text": "ColabFold is a fork of AlphaFold specifically designed for running on Google Colab resources. It is instantly accessible via Google Colab, or you can run the modified workflow on your own resources.\n\n\n\nGoogle Colab is an online Python Notebook platform. Notebooks are powered by reasonable CPU, RAM, and GPU resources are available freely, only requiring a Google account. You can pay for a professional account for access to additional resources, but the free-tier is very useful! You can run most Python packages and workflows within the Colab environment.\n\n\n\nThere are few variations that use different tools in the pipeline all available on the repo.\nThis first notebook simply searches an amino acid sequence against the known databases. The actual prediction can take some time, from minutes to hours, depending on the length of the protein and what type of GPU google provides (as it can randomly vary). Follow the steps here: AlphaFold Colab\nA more advanced version allows protein structure and complex prediction using AlphaFold2 and Alphafold2-multimer. Sequence alignments/templates are generated through MMseqs2 and HHsearch.\nFollow along: AlphaFold2 using MMseqs2\n\n\n\nYou cannot automate searches as robustly as on command-line. Google-Colab instances have time and computational resource limits on them."
  },
  {
    "objectID": "notebooks/07_colabfold.html#what-is-colabfold",
    "href": "notebooks/07_colabfold.html#what-is-colabfold",
    "title": "Running AlphaFold with ColabFold on Google Colab",
    "section": "",
    "text": "ColabFold is a fork of AlphaFold specifically designed for running on Google Colab resources. It is instantly accessible via Google Colab, or you can run the modified workflow on your own resources."
  },
  {
    "objectID": "notebooks/07_colabfold.html#what-is-google-colab",
    "href": "notebooks/07_colabfold.html#what-is-google-colab",
    "title": "Running AlphaFold with ColabFold on Google Colab",
    "section": "",
    "text": "Google Colab is an online Python Notebook platform. Notebooks are powered by reasonable CPU, RAM, and GPU resources are available freely, only requiring a Google account. You can pay for a professional account for access to additional resources, but the free-tier is very useful! You can run most Python packages and workflows within the Colab environment."
  },
  {
    "objectID": "notebooks/07_colabfold.html#how-do-i-run-alphafold-with-colabfold",
    "href": "notebooks/07_colabfold.html#how-do-i-run-alphafold-with-colabfold",
    "title": "Running AlphaFold with ColabFold on Google Colab",
    "section": "",
    "text": "There are few variations that use different tools in the pipeline all available on the repo.\nThis first notebook simply searches an amino acid sequence against the known databases. The actual prediction can take some time, from minutes to hours, depending on the length of the protein and what type of GPU google provides (as it can randomly vary). Follow the steps here: AlphaFold Colab\nA more advanced version allows protein structure and complex prediction using AlphaFold2 and Alphafold2-multimer. Sequence alignments/templates are generated through MMseqs2 and HHsearch.\nFollow along: AlphaFold2 using MMseqs2"
  },
  {
    "objectID": "notebooks/07_colabfold.html#what-are-the-limitations-of-colabfold",
    "href": "notebooks/07_colabfold.html#what-are-the-limitations-of-colabfold",
    "title": "Running AlphaFold with ColabFold on Google Colab",
    "section": "",
    "text": "You cannot automate searches as robustly as on command-line. Google-Colab instances have time and computational resource limits on them."
  },
  {
    "objectID": "notebooks/06_aws.html",
    "href": "notebooks/06_aws.html",
    "title": "Running AlphaFold on the the Sydney Research Cloud (Ronin AWS)",
    "section": "",
    "text": "If you find your workflows do not suit the queued environment of Gadi or Artemis, you may find creating your own computational stack to be most robust and adaptable.\nSydney offers researchers access to the AWS cloud via Ronin. This interface allows creation and configuration of virtual machines on-demand with as many computational resources as you need for your current workload.\nGenerally, you will start with a bare-bones virtual machine. You may then install AlphaFold and the corresponding databases as per the installation instructions:\nhttps://github.com/google-deepmind/alphafold\n\n\n\nYou may want to consult the native AWS AlphaFold installation instructions too, or the Google Cloud Platform configuration steps if you have ongoing AlphaFold requirements that can’t be satisfied by a local installation."
  },
  {
    "objectID": "notebooks/06_aws.html#ronin-research-cloud",
    "href": "notebooks/06_aws.html#ronin-research-cloud",
    "title": "Running AlphaFold on the the Sydney Research Cloud (Ronin AWS)",
    "section": "",
    "text": "If you find your workflows do not suit the queued environment of Gadi or Artemis, you may find creating your own computational stack to be most robust and adaptable.\nSydney offers researchers access to the AWS cloud via Ronin. This interface allows creation and configuration of virtual machines on-demand with as many computational resources as you need for your current workload.\nGenerally, you will start with a bare-bones virtual machine. You may then install AlphaFold and the corresponding databases as per the installation instructions:\nhttps://github.com/google-deepmind/alphafold"
  },
  {
    "objectID": "notebooks/06_aws.html#aws-and-gcp-public-clouds",
    "href": "notebooks/06_aws.html#aws-and-gcp-public-clouds",
    "title": "Running AlphaFold on the the Sydney Research Cloud (Ronin AWS)",
    "section": "",
    "text": "You may want to consult the native AWS AlphaFold installation instructions too, or the Google Cloud Platform configuration steps if you have ongoing AlphaFold requirements that can’t be satisfied by a local installation."
  },
  {
    "objectID": "notebooks/04_singularity.html",
    "href": "notebooks/04_singularity.html",
    "title": "Running AlphaFold in a Docker/Singularity Container",
    "section": "",
    "text": "Containers, in general, are a technology that enables the packaging and isolation of applications and their dependencies in a consistent environment. They offer a lightweight and efficient way to deploy software by bundling everything needed to run an application, including its code, runtime, libraries, and settings, into a single package called a container. This approach ensures that the application runs consistently across different environments, from development to production. Containers provide a more lightweight alternative to traditional virtual machines, as they share the host operating system’s kernel, resulting in faster startup times and reduced resource overhead. This technology is widely used to simplify application deployment, improve scalability, and enhance the consistency of software across various systems.\n\n\n\nDocker is a virtualization solution that streamlines the development and deployment of applications. This is achieved through the encapsulation of an application into a self-contained container. This container comprises not only the application’s code but also its entire assortment of libraries, dependencies, as well as runtime and environmental configurations. This self-contained nature ensures consistent execution across diverse settings, markedly easing the complexities associated with application distribution, execution, and reproducibility.\nThe officially recommend way to run local versions of AlphaFold is through containerisation.. This implementation orchestrates different parts of the analysis to run efficiently (on gpu, cpu, etc). The problem with the provided docker version is the requirement for elevated privileged access to the machine you are working on. This is difficult to accommodate in most shared facilities.\nThere are many different versions of AlphaFold installations that utilise docker to ultimately run. We provide several options for configuration and running AF optimised for Artemis. Although, you may use this container on any system that supports it.\n\n\n\nSingularity is a containerization tool designed with a focus on security and compatibility, particularly in high-performance computing and scientific computing environments. It allows you to encapsulate an application, including its code, libraries, and dependencies, into a single executable image. Unlike Docker, Singularity emphasizes process-level isolation and doesn’t require root privileges to run, making it well-suited for multi-user systems. It’s commonly used for creating self-contained, reproducible environments for complex computations and simulations.\n\n\nWe make use of our AlphaFold Docker images to build and run AF on Artemis. This is a two-step process. You must first build the docker image into a Singularity image. Then you may run it as below.\nNavigate to your project folder, e.g. cd /project/Training/AF\nFirst make a new jobscript for the build step, nano alpha_build.pbs:\n#!/bin/bash\n#PBS -P Training\n#PBS -l select=1:ncpus=2:mem=16gb:ngpus=0\n#PBS -l walltime=02:00:00\n#PBS -N build01\n\nmodule load singularity cuda/10.2.89\n\ncd $PBS_O_WORKDIR\nexport SINGULARITY_CACHEDIR=`pwd`\nexport SINGULARITY_TMPDIR=`pwd`\n\nsingularity build colab.img docker://sydneyinformaticshub/alphafold:colabfold_v1.3.0\nRun the build step with qsub alpha_build.pbs.\nYou only have to do this once. Alternatively, you can build the image offline and move the Singularity image to Artemis, or move this file anywhere else you wish to run with Singularity. Note, if you make any changes upstream to the Docker image, you must rebuild it to have those changes implemented.\nNext, make a jobscript to actually run the image, nano alpha_sing.pbs\n#!/bin/bash\n#PBS -P Training\n#PBS -l select=1:ncpus=8:mem=32gb:ngpus=1\n#PBS -l walltime=02:00:00\n#PBS -N job_colab01_gpu\n\nmodule load singularity cuda/10.2.89\n\ncd $PBS_O_WORKDIR\n\nsingularity run --nv /project/Training/DATA/colab.img /bin/bash -c \"colabfold_batch --templates --num-recycle 1 /project/Training/DATA/input.fasta \"$PBS_O_WORKDIR\"/output\"\n\n\n\n\nThis job takes around 8 minutes with 8 cpus, 32 gb ram, and 1 gpu. Incredibly fast to make a prediction compared with native AF (albeit with different parameters and quality of model results). Without the GPU it takes around 40 minutes.\n\n\n\nNote: You can grab a copy of the 8GB Singularity image and skip the build step!\nwget -O colab.img https://cloudstor.aarnet.edu.au/plus/s/OlBeNi6xNV9wBMr/download"
  },
  {
    "objectID": "notebooks/04_singularity.html#containers",
    "href": "notebooks/04_singularity.html#containers",
    "title": "Running AlphaFold in a Docker/Singularity Container",
    "section": "",
    "text": "Containers, in general, are a technology that enables the packaging and isolation of applications and their dependencies in a consistent environment. They offer a lightweight and efficient way to deploy software by bundling everything needed to run an application, including its code, runtime, libraries, and settings, into a single package called a container. This approach ensures that the application runs consistently across different environments, from development to production. Containers provide a more lightweight alternative to traditional virtual machines, as they share the host operating system’s kernel, resulting in faster startup times and reduced resource overhead. This technology is widely used to simplify application deployment, improve scalability, and enhance the consistency of software across various systems."
  },
  {
    "objectID": "notebooks/04_singularity.html#alphafold-with-docker",
    "href": "notebooks/04_singularity.html#alphafold-with-docker",
    "title": "Running AlphaFold in a Docker/Singularity Container",
    "section": "",
    "text": "Docker is a virtualization solution that streamlines the development and deployment of applications. This is achieved through the encapsulation of an application into a self-contained container. This container comprises not only the application’s code but also its entire assortment of libraries, dependencies, as well as runtime and environmental configurations. This self-contained nature ensures consistent execution across diverse settings, markedly easing the complexities associated with application distribution, execution, and reproducibility.\nThe officially recommend way to run local versions of AlphaFold is through containerisation.. This implementation orchestrates different parts of the analysis to run efficiently (on gpu, cpu, etc). The problem with the provided docker version is the requirement for elevated privileged access to the machine you are working on. This is difficult to accommodate in most shared facilities.\nThere are many different versions of AlphaFold installations that utilise docker to ultimately run. We provide several options for configuration and running AF optimised for Artemis. Although, you may use this container on any system that supports it."
  },
  {
    "objectID": "notebooks/04_singularity.html#alphafold-with-singularity",
    "href": "notebooks/04_singularity.html#alphafold-with-singularity",
    "title": "Running AlphaFold in a Docker/Singularity Container",
    "section": "",
    "text": "Singularity is a containerization tool designed with a focus on security and compatibility, particularly in high-performance computing and scientific computing environments. It allows you to encapsulate an application, including its code, libraries, and dependencies, into a single executable image. Unlike Docker, Singularity emphasizes process-level isolation and doesn’t require root privileges to run, making it well-suited for multi-user systems. It’s commonly used for creating self-contained, reproducible environments for complex computations and simulations.\n\n\nWe make use of our AlphaFold Docker images to build and run AF on Artemis. This is a two-step process. You must first build the docker image into a Singularity image. Then you may run it as below.\nNavigate to your project folder, e.g. cd /project/Training/AF\nFirst make a new jobscript for the build step, nano alpha_build.pbs:\n#!/bin/bash\n#PBS -P Training\n#PBS -l select=1:ncpus=2:mem=16gb:ngpus=0\n#PBS -l walltime=02:00:00\n#PBS -N build01\n\nmodule load singularity cuda/10.2.89\n\ncd $PBS_O_WORKDIR\nexport SINGULARITY_CACHEDIR=`pwd`\nexport SINGULARITY_TMPDIR=`pwd`\n\nsingularity build colab.img docker://sydneyinformaticshub/alphafold:colabfold_v1.3.0\nRun the build step with qsub alpha_build.pbs.\nYou only have to do this once. Alternatively, you can build the image offline and move the Singularity image to Artemis, or move this file anywhere else you wish to run with Singularity. Note, if you make any changes upstream to the Docker image, you must rebuild it to have those changes implemented.\nNext, make a jobscript to actually run the image, nano alpha_sing.pbs\n#!/bin/bash\n#PBS -P Training\n#PBS -l select=1:ncpus=8:mem=32gb:ngpus=1\n#PBS -l walltime=02:00:00\n#PBS -N job_colab01_gpu\n\nmodule load singularity cuda/10.2.89\n\ncd $PBS_O_WORKDIR\n\nsingularity run --nv /project/Training/DATA/colab.img /bin/bash -c \"colabfold_batch --templates --num-recycle 1 /project/Training/DATA/input.fasta \"$PBS_O_WORKDIR\"/output\""
  },
  {
    "objectID": "notebooks/04_singularity.html#timing",
    "href": "notebooks/04_singularity.html#timing",
    "title": "Running AlphaFold in a Docker/Singularity Container",
    "section": "",
    "text": "This job takes around 8 minutes with 8 cpus, 32 gb ram, and 1 gpu. Incredibly fast to make a prediction compared with native AF (albeit with different parameters and quality of model results). Without the GPU it takes around 40 minutes."
  },
  {
    "objectID": "notebooks/04_singularity.html#colabfold-singularity-image",
    "href": "notebooks/04_singularity.html#colabfold-singularity-image",
    "title": "Running AlphaFold in a Docker/Singularity Container",
    "section": "",
    "text": "Note: You can grab a copy of the 8GB Singularity image and skip the build step!\nwget -O colab.img https://cloudstor.aarnet.edu.au/plus/s/OlBeNi6xNV9wBMr/download"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AlphaFold",
    "section": "",
    "text": "This is a training course aimed at users wanting to learn about AlphaFold to perform predictions of protein structures. Beyond an introduction to the capabilities of AlphaFold, topics will cover different techincal approaches to run AlphaFold including using High Performance Computing and Cloud environments."
  },
  {
    "objectID": "index.html#trainers",
    "href": "index.html#trainers",
    "title": "AlphaFold",
    "section": "Trainers",
    "text": "Trainers\n\nChristopher Le\nJake Chen FMH\nNathaniel Butterworth SIH"
  },
  {
    "objectID": "index.html#course-pre-requisites-and-setup-requirements",
    "href": "index.html#course-pre-requisites-and-setup-requirements",
    "title": "AlphaFold",
    "section": "Course pre-requisites and setup requirements",
    "text": "Course pre-requisites and setup requirements\nNo previous programming experience is required, this training course will introduce you to fundamental Unix and HPC as required. Training will be delivered online, so you will need access to a modern computer with a stable internet connection. Participants will require the Sydney VPN and a terminal client (as per the Setup Instructions provided)."
  },
  {
    "objectID": "index.html#venue",
    "href": "index.html#venue",
    "title": "AlphaFold",
    "section": "Venue",
    "text": "Venue\nOnline via Zoom, a link will be shared with registered participants.\n\nZoom etiquette and how we interact\nSessions will be recorded and added to this page. Please interrupt whenever you want! Ideally, have your camera on and interact as much as possible. There will be someone monitoring the chat-window for any questions you would like to post there. Extending for a three-hour duration, our Zoom session incorporates regular breaks and a blend of demonstrative and hands-on material."
  },
  {
    "objectID": "index.html#code-of-conduct",
    "href": "index.html#code-of-conduct",
    "title": "AlphaFold",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nAs a University of Sydney course, we also want to make sure peopele are aware of our code of conduct. Feel free to move this to an about page as needed.\nExample standard Code of Conduct statement:\nWe expect all attendees of our training to follow our code of conduct, including bullying, harassment and discrimination prevention policies.\nIn order to foster a positive and professional learning environment we encourage the following kinds of behaviours at all our events and on our platforms:\n\nUse welcoming and inclusive language\nBe respectful of different viewpoints and experiences\nGracefully accept constructive criticism\nFocus on what is best for the community\nShow courtesy and respect towards other community members\n\nOur full CoC, with incident reporting guidelines, is available Here."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "AlphaFold",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nIn-depth\n\n\n\n\nIntro to AlphaFold\n\n\n\nColabFold\n\n\n\nIntro to HPC\n\n\n\nArtemis Example\n\n\nOptional Topics\n\n\n\n\nSingularity Example\n\n\n\nNCI Example\n\n\n\nRonin Research Cloud (AWS) Example\n\n\n\nBiocommons Example"
  },
  {
    "objectID": "index.html#setup-instructions",
    "href": "index.html#setup-instructions",
    "title": "AlphaFold",
    "section": "Setup Instructions",
    "text": "Setup Instructions\nPlease attempt to complete the Setup Instructions before the course. We will run through this in the course too."
  },
  {
    "objectID": "CHEATSHEET.html",
    "href": "CHEATSHEET.html",
    "title": "Quarto template cheatsheet",
    "section": "",
    "text": "Quarto template cheatsheet\nPlease contribute your tips, tricks for use, customisation of this template :)"
  },
  {
    "objectID": "notebooks/01_alphafold.html",
    "href": "notebooks/01_alphafold.html",
    "title": "Introduction to AlphaFold",
    "section": "",
    "text": "AlphaFold is a groundbreaking artificial intelligence system developed by DeepMind that focuses on predicting the three-dimensional structure of proteins. Proteins are essential molecules in our bodies that carry out various functions, and their structure plays a critical role in understanding their behaviour and function.\nAlphaFold2 utilises deep learning algorithms to analyse the amino acid sequence of a protein and predict its 3D structure accurately. By understanding the structure of proteins, scientists can gain insights into how they interact with other molecules, such as drugs, and how they function in biological processes. This knowledge can have profound implications for various fields, including medicine, drug discovery, and bioengineering.\nThe traditional methods for determining protein structures, such as X-ray crystallography and cryo-electron microscopy, can be time-consuming and expensive. AlphaFold2 significantly accelerates this process by providing accurate predictions in a fraction of the time. Its predictions have shown remarkable accuracy, comparable to experimental methods.\nBy providing researchers with reliable protein structure predictions, AlphaFold2 has the potential to revolutionise our understanding of biology and accelerate scientific discoveries. It can aid in designing more effective drugs, understanding disease mechanisms, and developing enzymes for industrial applications. Ultimately, AlphaFold2’s advancements in protein folding have the potential to transform multiple areas of research and have a profound impact on human health and well-being.\nThe original AlphaFold was introduced in 2018 and utilised deep learning techniques to predict protein structures. It made significant advancements in protein folding predictions compared to previous methods but still had limitations in accuracy.\nAlphaFold v2, introduced in 2020, represents a major breakthrough in protein structure prediction. It incorporates novel algorithmic improvements and advanced machine learning techniques, including a deep neural network architecture, to significantly improve accuracy. AlphaFold2 achieved remarkable performance in the Critical Assessment of Structure Prediction (CASP) competition in 2020, outperforming other methods and approaching experimental accuracy for many protein structures.\nAlphaFold2 is computationally optimised and can deliver predictions within a matter of days, or even hours, for many proteins. Moreover, AlphaFold2 has been designed with scalability in mind. It can efficiently utilise distributed computing resources, enabling multiple protein structure predictions to be processed simultaneously.\nAlphaFold2 incorporates an attention mechanism that allows it to focus on relevant parts of the protein sequence when making predictions. This attention mechanism provides insights into the model’s decision-making process and makes it more interpretable than the original AlphaFold.\nHere is a good introductory video into AlphaFold by SciShow: How AI Could Change Biology\n\n\nIf you only want to predict a small number of naturally occuring proteins, use the online ColabFold notebook or download the structures from the AlphaFold2 Protein Structure Database. These are accessed through a web browser, allowing users to submit protein sequences and receive predicted structures via an online interface. It provides a user-friendly graphical interface that makes it accessible to non-experts and researchers without extensive programming or command line experience.\nThe AlphaFold2 Protein Structure Database is primarily intended for users who want to obtain protein structure predictions quickly and conveniently without the need for complex setups. Users can submit protein sequences, and the database provides predicted structures as outputs. It offers a straightforward interface with pre-defined settings and options.\n\n\n\nAutomation (via AlphaFold or LocalColabFold or similar) is suitable for more advanced applications such as batch processing of structure predictions for non-natural proteins and complexes, or predictions with manually specified MSAs / templates.\nThe command line AlphaFold2 application is a software package that runs on a local machine or server. It is designed for advanced users and researchers familiar with command line interfaces and programming. It requires installation and configuration, but it offers more flexibility and control over the prediction process.\nIt is customisable and allows researchers to fine-tune the prediction process according to their specific requirements. It provides a wide range of command line options and parameters that can be modified to optimise predictions. This level of control is beneficial for researchers who want to experiment with different settings or integrate AlphaFold2 into their existing computational pipelines.\nThis course is aimed at researchers seeking to automate their use of AlphaFold. See the following pages for examples for how to use AlphaFold in different conditions and on different systems. Whilst these are targeted for Sydney University researchers, others may benefit from the general routines.\n\n\n\nAlphaFold is mostly driven by the use of FASTA files.\nA FASTA (pronounced “fast-ay”) file is a common plain text format used to store biological sequence data, such as DNA, RNA, or protein sequences. It is named after the FASTA software package, which originally introduced this format. FASTA files consist of two main components:\nHeader: The header line begins with a “&gt;” symbol, followed by a unique identifier for the sequence. This identifier can contain information about the sequence, like its source or other relevant details.\nSequence Data: The following lines contain the actual sequence data, which can be composed of letters representing nucleotides (A, T, C, G, U) for DNA, RNA sequences or amino acids (A, R, N, etc.) for protein sequences.\nFro example:\n&gt;MCHU - Calmodulin - Human, rabbit, bovine, rat, and chicken\nMADQLTEEQIAEFKEAFSLFDKDGDGTITTKELGTVMRSLGQNPTEAELQDMINEVDADGNGTID\nFPEFLTMMARKMKDTDSEEEIREAFRVFDKDGNGYISAAELRHVMTNLGEKLTDEEVDEMIREA\nDIDGDGQVNYEEFVQMMTAK*\nFASTA files are easy to read by both humans and computers, making them a standard format for sharing and storing biological sequence information. They are used in various bioinformatics applications, including sequence analysis, sequence alignment, database searches, and data exchange between different software tools and databases.\n\n\n\n\nProtein Structure Prediction: Understanding the 3D structure of proteins is crucial because a protein’s function is intricately linked to its shape. By accurately predicting protein structures, researchers can gain insights into their functions, interactions, and potential roles in various biological processes.\n\nrun_alphafold.py input.fasta ...\nAt it’s core, AlphaFold needs a FASTA file to make predictions.\n\nDrug Discovery: Many diseases are caused by malfunctioning proteins. Interpreting the accurate protein structure predictions, researchers can identify potential drug targets and design molecules that specifically interact with the target protein, leading to the development of new drugs and therapies.\nBiological Research: AlphaFold aids researchers in studying the underlying mechanisms of biological processes. Protein structures provide insights into how proteins function, interact with other molecules, and carry out their roles in cells. One may use the predicted protein structures as input for docking simulations to study protein-protein interactions, for example:\n\nrosetta_scripts -s receptor.pdb -l ligand.pdb -parser:protocol docking.xml -score:weights ref15.wts\nWhere receptor.pdb is the AlphaFold output, ligand.pdb is the ligand structure, and docking.xml is a RosettaScripts protocol file for docking simulations.\n\nDisease Understanding: Knowing the structures of proteins associated with diseases helps researchers understand how these proteins contribute to the disease’s development. This understanding can pave the way for novel therapeutic approaches where you may use predicted structures in molecular dynamics simulations to understand how mutations affect protein stability:\n\ngromacs grompp -f md.mdp -c input.gro -p topol.top -o md.tpr\ngromacs mdrun -v -deffnm md\nWhere md.mdp is the GROMACS configuration file, input.gro is the structure predicted by AlphaFold (converted from .pdb), and topol.top is the topology file.\n\nEngineering and Design: AlphaFold can assist in protein engineering by designing proteins with specific functions or properties, such as creating enzymes with improved catalytic activities or generating novel protein structures for industrial applications.\n\nrosetta_scripts -s starting_structure.pdb -parser:protocol design.xml -score:weights ref15.wts\nWhere starting_structure.pdb is the input structure from AlphaFold, design.xml is a RosettaScripts protocol file for design, and ref15.wts are the scoring weights.\n\nBioinformatics and Data Interpretation: AlphaFold’s predictions can complement experimental data, helping researchers interpret experimental results and guiding further experiments. It can provide structural context to help explain biochemical and genetic observations, and predictions may integrated into analysis pipelines.\nFunctional Annotations: Predicting protein structures can aid in annotating the functions of newly sequenced genes and proteins, especially when experimental data is limited. One can compare AlphaFold predictions to known protein structures and functions using tools like BLAST or Pfam:\n\nblastp -query query.fasta -db nr -out results.txt -evalue 1e-5 -outfmt 6\nWhere query.fasta is your FASTA sequence, and nr is the BLAST database.\nAkdel, M., Pires, D.E.V., Pardo, E.P. et al. A structural biology community assessment of AlphaFold2 applications. Nat Struct Mol Biol 29, 1056–1067 (2022). https://doi.org/10.1038/s41594-022-00849-w\n\nReducing Experimental Costs: Determining protein structures experimentally using methods like X-ray crystallography or nuclear magnetic resonance (NMR) can be time-consuming and expensive. AlphaFold’s predictions can provide a cost-effective alternative to obtaining initial structural information and prioritising which proteins to study experimentally.\n\n\n\n\nIf you use the AlphaFold code or data, please cite:\n@Article{AlphaFold2021,\n  author  = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green,\n            Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool,\n            Kathryn and Bates, Russ and {\\v{Z}}{\\'\\i}dek, Augustin and Potapenko,\n            Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A A and Ballard,\n            Andrew J and Cowie, Andrew and Romera-Paredes, Bernardino and Nikolov,\n            Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen,\n            Stig and Reiman, David and Clancy, Ellen and Zielinski,\n            Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer,\n            Tamas and Bodenstein, Sebastian and Silver, David and Vinyals,\n            Oriol and Senior, Andrew W and Kavukcuoglu, Koray and Kohli,\n            Pushmeet and Hassabis, Demis},\n  journal = {Nature},\n  title   = {Highly accurate protein structure prediction with {AlphaFold}},\n  year    = {2021},\n  volume  = {596},\n  number  = {7873},\n  pages   = {583--589},\n  doi     = {10.1038/s41586-021-03819-2}\n}"
  },
  {
    "objectID": "notebooks/01_alphafold.html#manual-database-search",
    "href": "notebooks/01_alphafold.html#manual-database-search",
    "title": "Introduction to AlphaFold",
    "section": "",
    "text": "If you only want to predict a small number of naturally occuring proteins, use the online ColabFold notebook or download the structures from the AlphaFold2 Protein Structure Database. These are accessed through a web browser, allowing users to submit protein sequences and receive predicted structures via an online interface. It provides a user-friendly graphical interface that makes it accessible to non-experts and researchers without extensive programming or command line experience.\nThe AlphaFold2 Protein Structure Database is primarily intended for users who want to obtain protein structure predictions quickly and conveniently without the need for complex setups. Users can submit protein sequences, and the database provides predicted structures as outputs. It offers a straightforward interface with pre-defined settings and options."
  },
  {
    "objectID": "notebooks/01_alphafold.html#automation",
    "href": "notebooks/01_alphafold.html#automation",
    "title": "Introduction to AlphaFold",
    "section": "",
    "text": "Automation (via AlphaFold or LocalColabFold or similar) is suitable for more advanced applications such as batch processing of structure predictions for non-natural proteins and complexes, or predictions with manually specified MSAs / templates.\nThe command line AlphaFold2 application is a software package that runs on a local machine or server. It is designed for advanced users and researchers familiar with command line interfaces and programming. It requires installation and configuration, but it offers more flexibility and control over the prediction process.\nIt is customisable and allows researchers to fine-tune the prediction process according to their specific requirements. It provides a wide range of command line options and parameters that can be modified to optimise predictions. This level of control is beneficial for researchers who want to experiment with different settings or integrate AlphaFold2 into their existing computational pipelines.\nThis course is aimed at researchers seeking to automate their use of AlphaFold. See the following pages for examples for how to use AlphaFold in different conditions and on different systems. Whilst these are targeted for Sydney University researchers, others may benefit from the general routines."
  },
  {
    "objectID": "notebooks/01_alphafold.html#fasta-format",
    "href": "notebooks/01_alphafold.html#fasta-format",
    "title": "Introduction to AlphaFold",
    "section": "",
    "text": "AlphaFold is mostly driven by the use of FASTA files.\nA FASTA (pronounced “fast-ay”) file is a common plain text format used to store biological sequence data, such as DNA, RNA, or protein sequences. It is named after the FASTA software package, which originally introduced this format. FASTA files consist of two main components:\nHeader: The header line begins with a “&gt;” symbol, followed by a unique identifier for the sequence. This identifier can contain information about the sequence, like its source or other relevant details.\nSequence Data: The following lines contain the actual sequence data, which can be composed of letters representing nucleotides (A, T, C, G, U) for DNA, RNA sequences or amino acids (A, R, N, etc.) for protein sequences.\nFro example:\n&gt;MCHU - Calmodulin - Human, rabbit, bovine, rat, and chicken\nMADQLTEEQIAEFKEAFSLFDKDGDGTITTKELGTVMRSLGQNPTEAELQDMINEVDADGNGTID\nFPEFLTMMARKMKDTDSEEEIREAFRVFDKDGNGYISAAELRHVMTNLGEKLTDEEVDEMIREA\nDIDGDGQVNYEEFVQMMTAK*\nFASTA files are easy to read by both humans and computers, making them a standard format for sharing and storing biological sequence information. They are used in various bioinformatics applications, including sequence analysis, sequence alignment, database searches, and data exchange between different software tools and databases."
  },
  {
    "objectID": "notebooks/01_alphafold.html#alphafold-use-cases",
    "href": "notebooks/01_alphafold.html#alphafold-use-cases",
    "title": "Introduction to AlphaFold",
    "section": "",
    "text": "Protein Structure Prediction: Understanding the 3D structure of proteins is crucial because a protein’s function is intricately linked to its shape. By accurately predicting protein structures, researchers can gain insights into their functions, interactions, and potential roles in various biological processes.\n\nrun_alphafold.py input.fasta ...\nAt it’s core, AlphaFold needs a FASTA file to make predictions.\n\nDrug Discovery: Many diseases are caused by malfunctioning proteins. Interpreting the accurate protein structure predictions, researchers can identify potential drug targets and design molecules that specifically interact with the target protein, leading to the development of new drugs and therapies.\nBiological Research: AlphaFold aids researchers in studying the underlying mechanisms of biological processes. Protein structures provide insights into how proteins function, interact with other molecules, and carry out their roles in cells. One may use the predicted protein structures as input for docking simulations to study protein-protein interactions, for example:\n\nrosetta_scripts -s receptor.pdb -l ligand.pdb -parser:protocol docking.xml -score:weights ref15.wts\nWhere receptor.pdb is the AlphaFold output, ligand.pdb is the ligand structure, and docking.xml is a RosettaScripts protocol file for docking simulations.\n\nDisease Understanding: Knowing the structures of proteins associated with diseases helps researchers understand how these proteins contribute to the disease’s development. This understanding can pave the way for novel therapeutic approaches where you may use predicted structures in molecular dynamics simulations to understand how mutations affect protein stability:\n\ngromacs grompp -f md.mdp -c input.gro -p topol.top -o md.tpr\ngromacs mdrun -v -deffnm md\nWhere md.mdp is the GROMACS configuration file, input.gro is the structure predicted by AlphaFold (converted from .pdb), and topol.top is the topology file.\n\nEngineering and Design: AlphaFold can assist in protein engineering by designing proteins with specific functions or properties, such as creating enzymes with improved catalytic activities or generating novel protein structures for industrial applications.\n\nrosetta_scripts -s starting_structure.pdb -parser:protocol design.xml -score:weights ref15.wts\nWhere starting_structure.pdb is the input structure from AlphaFold, design.xml is a RosettaScripts protocol file for design, and ref15.wts are the scoring weights.\n\nBioinformatics and Data Interpretation: AlphaFold’s predictions can complement experimental data, helping researchers interpret experimental results and guiding further experiments. It can provide structural context to help explain biochemical and genetic observations, and predictions may integrated into analysis pipelines.\nFunctional Annotations: Predicting protein structures can aid in annotating the functions of newly sequenced genes and proteins, especially when experimental data is limited. One can compare AlphaFold predictions to known protein structures and functions using tools like BLAST or Pfam:\n\nblastp -query query.fasta -db nr -out results.txt -evalue 1e-5 -outfmt 6\nWhere query.fasta is your FASTA sequence, and nr is the BLAST database.\nAkdel, M., Pires, D.E.V., Pardo, E.P. et al. A structural biology community assessment of AlphaFold2 applications. Nat Struct Mol Biol 29, 1056–1067 (2022). https://doi.org/10.1038/s41594-022-00849-w\n\nReducing Experimental Costs: Determining protein structures experimentally using methods like X-ray crystallography or nuclear magnetic resonance (NMR) can be time-consuming and expensive. AlphaFold’s predictions can provide a cost-effective alternative to obtaining initial structural information and prioritising which proteins to study experimentally."
  },
  {
    "objectID": "notebooks/01_alphafold.html#citations",
    "href": "notebooks/01_alphafold.html#citations",
    "title": "Introduction to AlphaFold",
    "section": "",
    "text": "If you use the AlphaFold code or data, please cite:\n@Article{AlphaFold2021,\n  author  = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green,\n            Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool,\n            Kathryn and Bates, Russ and {\\v{Z}}{\\'\\i}dek, Augustin and Potapenko,\n            Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A A and Ballard,\n            Andrew J and Cowie, Andrew and Romera-Paredes, Bernardino and Nikolov,\n            Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen,\n            Stig and Reiman, David and Clancy, Ellen and Zielinski,\n            Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer,\n            Tamas and Bodenstein, Sebastian and Silver, David and Vinyals,\n            Oriol and Senior, Andrew W and Kavukcuoglu, Koray and Kohli,\n            Pushmeet and Hassabis, Demis},\n  journal = {Nature},\n  title   = {Highly accurate protein structure prediction with {AlphaFold}},\n  year    = {2021},\n  volume  = {596},\n  number  = {7873},\n  pages   = {583--589},\n  doi     = {10.1038/s41586-021-03819-2}\n}"
  },
  {
    "objectID": "notebooks/02_hpc.html",
    "href": "notebooks/02_hpc.html",
    "title": "Introduction to the High Performance Computing",
    "section": "",
    "text": "HPC stands for ‘High Performance Computing’, our local HPC is called “Artemis”. You might colloquially refer to Artemis as a ‘supercomputer’. Technically, Artemis is a computing cluster, which is a whole lot of individual computers networked together. AS of 2023, Artemis consists of:\n* 7,636 cores (CPUs)\n* 45 TB of RAM\n* 108 NVIDIA V100 GPUs\n* 378 TB of storage\n* 56 Gbps FDR InfiniBand (networking)\nArtemis computers (which we call machines or nodes) run a Linux operating system, ‘CentOS’ v6.10. Computing performed on Artemis nodes is managed by a scheduler, and ours is an instance of PBS Pro.\nArtemis is ideal for calculations that require:\n* A long time to complete (long walltime)\n* High RAM usage\n* Big data input or outputs\n* Are able to use multiple cores or nodes to run in parallel, and hence much faster\nIf you do use Artemis for your research, please acknowledge us! This ensures that we continue to get the funding we need to provide you with what is really a first-grade computing resource. A suggested acknowledgment might say:\n\nThe authors acknowledge the Sydney Informatics Hub and the University of Sydney’s high performance computing cluster, Artemis, for providing the computing resources that have contributed to the results reported herein.\n\n\n\n\nGet an Artemis account by creating a project with Artemis HPC access in Researcher Dashboard (DashR).\nArtemis is available free of charge to all University of Sydney researchers. You only need a unikey, and a valid Research Dashboard Research Data Management Plan with Artemis access enabled.\nDuring the course you can be issued with an account belonging to the Training project.\n\n\n\nConnections to Artemis are remote connections – you’ll never sit at one of Artemis’ machines, which are stored in a secure data-centre in Western Sydney. Instead, you connect remotely into one of Artemis’ login nodes. Login nodes are Artemis machines that don’t perform any actual computing jobs, but simply provide users with an access gateway to Artemis’ filesystems and the PBS Pro job scheduler.\nYou can thus connect to Artemis from anywhere, requiring only a terminal emulator with an SSH client. (If you’re not on the USyd network (ie off-campus), you’ll also need to connect to the University’s VPN.\nIf you followed the Setup instructions, then you should already have the required software installed.\nOnce you are set up with an ssh client, connect with your unikey credentials with:\nssh -X &lt;unikey&gt;@hpc.sydney.edu.au"
  },
  {
    "objectID": "notebooks/02_hpc.html#what-is-the-artemis-hpc",
    "href": "notebooks/02_hpc.html#what-is-the-artemis-hpc",
    "title": "Introduction to the High Performance Computing",
    "section": "",
    "text": "HPC stands for ‘High Performance Computing’, our local HPC is called “Artemis”. You might colloquially refer to Artemis as a ‘supercomputer’. Technically, Artemis is a computing cluster, which is a whole lot of individual computers networked together. AS of 2023, Artemis consists of:\n* 7,636 cores (CPUs)\n* 45 TB of RAM\n* 108 NVIDIA V100 GPUs\n* 378 TB of storage\n* 56 Gbps FDR InfiniBand (networking)\nArtemis computers (which we call machines or nodes) run a Linux operating system, ‘CentOS’ v6.10. Computing performed on Artemis nodes is managed by a scheduler, and ours is an instance of PBS Pro.\nArtemis is ideal for calculations that require:\n* A long time to complete (long walltime)\n* High RAM usage\n* Big data input or outputs\n* Are able to use multiple cores or nodes to run in parallel, and hence much faster\nIf you do use Artemis for your research, please acknowledge us! This ensures that we continue to get the funding we need to provide you with what is really a first-grade computing resource. A suggested acknowledgment might say:\n\nThe authors acknowledge the Sydney Informatics Hub and the University of Sydney’s high performance computing cluster, Artemis, for providing the computing resources that have contributed to the results reported herein."
  },
  {
    "objectID": "notebooks/02_hpc.html#getting-an-artemis-account",
    "href": "notebooks/02_hpc.html#getting-an-artemis-account",
    "title": "Introduction to the High Performance Computing",
    "section": "",
    "text": "Get an Artemis account by creating a project with Artemis HPC access in Researcher Dashboard (DashR).\nArtemis is available free of charge to all University of Sydney researchers. You only need a unikey, and a valid Research Dashboard Research Data Management Plan with Artemis access enabled.\nDuring the course you can be issued with an account belonging to the Training project."
  },
  {
    "objectID": "notebooks/02_hpc.html#connecting-to-artemis",
    "href": "notebooks/02_hpc.html#connecting-to-artemis",
    "title": "Introduction to the High Performance Computing",
    "section": "",
    "text": "Connections to Artemis are remote connections – you’ll never sit at one of Artemis’ machines, which are stored in a secure data-centre in Western Sydney. Instead, you connect remotely into one of Artemis’ login nodes. Login nodes are Artemis machines that don’t perform any actual computing jobs, but simply provide users with an access gateway to Artemis’ filesystems and the PBS Pro job scheduler.\nYou can thus connect to Artemis from anywhere, requiring only a terminal emulator with an SSH client. (If you’re not on the USyd network (ie off-campus), you’ll also need to connect to the University’s VPN.\nIf you followed the Setup instructions, then you should already have the required software installed.\nOnce you are set up with an ssh client, connect with your unikey credentials with:\nssh -X &lt;unikey&gt;@hpc.sydney.edu.au"
  },
  {
    "objectID": "notebooks/08_biocommons.html",
    "href": "notebooks/08_biocommons.html",
    "title": "Running AlphaFold on Biocommons Galaxy",
    "section": "",
    "text": "The Australian Biocommons is a digital capability aimed at enhancing Australian research in its ability to understand the molecular basis of life across environmental, agricultural and biomedical science.\n\n\n\nGalaxy Australia is an open, web-based platform for accessible, reproducible and transparent computational research.\nYou must first register for Galaxy access using your Sydney credentials. This will give you access to the hundreds of bioinformatics tools on the platform.\nHowever, for access to AlphaFold an additional step must be made. Once registered with Galaxy fill in this form to use AlphaFold.\n\n\n\nOnce you have access, searching for AlphaFold in the left hand menu will bring up the tool.\nFill in the options and then click Run Tool!\nFrom your dashboard on Galaxy, you can share any results you generate with the world: https://usegalaxy.org.au/datasets/a6e389a98c2d1678f2d92efc723dec14/preview"
  },
  {
    "objectID": "notebooks/08_biocommons.html#austrlalian-biocommons",
    "href": "notebooks/08_biocommons.html#austrlalian-biocommons",
    "title": "Running AlphaFold on Biocommons Galaxy",
    "section": "",
    "text": "The Australian Biocommons is a digital capability aimed at enhancing Australian research in its ability to understand the molecular basis of life across environmental, agricultural and biomedical science."
  },
  {
    "objectID": "notebooks/08_biocommons.html#galaxy-australia",
    "href": "notebooks/08_biocommons.html#galaxy-australia",
    "title": "Running AlphaFold on Biocommons Galaxy",
    "section": "",
    "text": "Galaxy Australia is an open, web-based platform for accessible, reproducible and transparent computational research.\nYou must first register for Galaxy access using your Sydney credentials. This will give you access to the hundreds of bioinformatics tools on the platform.\nHowever, for access to AlphaFold an additional step must be made. Once registered with Galaxy fill in this form to use AlphaFold."
  },
  {
    "objectID": "notebooks/08_biocommons.html#alphafold-on-galaxy",
    "href": "notebooks/08_biocommons.html#alphafold-on-galaxy",
    "title": "Running AlphaFold on Biocommons Galaxy",
    "section": "",
    "text": "Once you have access, searching for AlphaFold in the left hand menu will bring up the tool.\nFill in the options and then click Run Tool!\nFrom your dashboard on Galaxy, you can share any results you generate with the world: https://usegalaxy.org.au/datasets/a6e389a98c2d1678f2d92efc723dec14/preview"
  },
  {
    "objectID": "notebooks/05_nci.html",
    "href": "notebooks/05_nci.html",
    "title": "Running AlphaFold on NCI Gadi HPC",
    "section": "",
    "text": "The ColabFold version of AlphaFold is available on NCI’s Gadi. Gadi is more than 10x larger than Artemis, so offers potentially far more significant resources.\nGadi uses a general architecture similar to Artemis so any workflows you have developed can be readily adapted to run on Gadi.\nUsage and example PBS jobscripts for AlphaFold are well-documented here: NCI Help - Colabfold\nYou may also shift your Singularity images and workflows to Gadi.\nFor access to NCI, see https://nci.org.au/users/how-access-nci or contact sih.info@sydney.edu.au\nOnce you have an account you will need to join the “Colab Fold Project - if89: Australia BioCommons Tools and Workflows”. To request access to this project visit: https://my.nci.org.au/mancini/project/if89"
  },
  {
    "objectID": "notebooks/05_nci.html#nci-gadi",
    "href": "notebooks/05_nci.html#nci-gadi",
    "title": "Running AlphaFold on NCI Gadi HPC",
    "section": "",
    "text": "The ColabFold version of AlphaFold is available on NCI’s Gadi. Gadi is more than 10x larger than Artemis, so offers potentially far more significant resources.\nGadi uses a general architecture similar to Artemis so any workflows you have developed can be readily adapted to run on Gadi.\nUsage and example PBS jobscripts for AlphaFold are well-documented here: NCI Help - Colabfold\nYou may also shift your Singularity images and workflows to Gadi.\nFor access to NCI, see https://nci.org.au/users/how-access-nci or contact sih.info@sydney.edu.au\nOnce you have an account you will need to join the “Colab Fold Project - if89: Australia BioCommons Tools and Workflows”. To request access to this project visit: https://my.nci.org.au/mancini/project/if89"
  }
]